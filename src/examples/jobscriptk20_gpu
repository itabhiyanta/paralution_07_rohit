#!/bin/bash
#$ -pe openmpi 1 
#$ -l h_rt=2:15:00
#$ -l fat,gpu=K20
#$ -N pdpcg_ongpu_guus1e7_16_meiluilu01_1e6
#$ -cwd

APP=./dpcg_precon
#ARGS=" A x b phi openMP_threads xdim ydim zdim lssd_vex_flag defvex_x defvex_y defvex_z levelset_ghost_points
# ARGS="/var/scratch/rgupta/dimitar_tsts_dec2013/AC32_9bub_lssd.mtx  /var/scratch/rgupta/dimitar_tsts_dec2013/x_readin32_9bub_lssd.rec /var/scratch/rgupta/dimitar_tsts_dec2013/b_readin32_9bub_lssd.rec /var/scratch/rgupta/dimitar_tsts_dec2013/phi_readin32_9bub_lssd.rec 32 1 4 2"
# ARGS="../../../convert_coo_to_mm/a_63_16_1e7.mtx ../../../convert_coo_to_mm/Z_63_16_1e7.mtx ../../../convert_coo_to_mm/r_63_16_1e7.dat 8"
#ARGS="/var/scratch/rgupta/guus_data/a_shell_inv.mtx /var/scratch/rgupta/guus_data/Z_shell_inv.mtx /var/scratch/rgupta/guus_data/r_shell_inv.dat /var/scratch/rgupta/guus_data/sol_shell_inv.dat 8"
#ARGS="/var/scratch/rgupta/guus_data/a_shell_norm.mtx /var/scratch/rgupta/guus_data/Z_shell_norm.mtx /var/scratch/rgupta/guus_data/r_shell_norm.dat /var/scratch/rgupta/guus_data/sol_shell_norm.dat 8"
ARGS="/var/scratch/rgupta/guus_data/a_shell_norm1e7_16.mtx /var/scratch/rgupta/guus_data/Z_shell_norm1e7_16.mtx /var/scratch/rgupta/guus_data/r_shell_nrm1e7_16.dat /var/scratch/rgupta/guus_data/sol_shell_nrm1e7_16.dat 8"
# Get OpenMPI settings
. /etc/bashrc
module load openmpi/gcc
module load cuda55/toolkit cuda55/profiler cuda55/blas
# Make new hostfile specifying the cores per node wanted
ncores=1
HOSTFILE=$TMPDIR/hosts
for host in `uniq $TMPDIR/machines`; do
    echo $host slots=$ncores
    done > $HOSTFILE
    nhosts=`wc -l < $HOSTFILE`
    totcores=`expr $nhosts \* $ncores`

# Use regular ssh-based startup instead of OpenMPI/SGE native one
unset PE_HOSTFILE
PATH=/usr/bin:$PATH
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/ROHIT/babysteps/paralution-0.7.0/build/lib
$MPI_RUN -np $totcores --hostfile $HOSTFILE $APP $ARGS
